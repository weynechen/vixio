# Qwen Pipeline Mode (Default)
# Stable, controllable, production-ready
#
# Architecture:
#   Audio → VAD → TurnDetector → ASR → TextAggregator → Agent → SentenceAggregator → TTS → Audio
#
# Requirements:
#   - DashScope API Key (for ASR, TTS, LLM)
#   - Install: pip install vixio[quickstart]
#
# Usage:
#   uvx vixio run xiaozhi-server --dashscope-key sk-xxx

providers:
  # VAD Provider (Local - Silero ONNX)
  # In-process voice activity detection, no external service needed
  vad:
    provider: silero-vad-local
    config:
      threshold: 0.35              # Voice detection threshold
      threshold_low: 0.15          # Lower threshold for hysteresis
      frame_window_threshold: 8    # Frames needed to confirm silence
      use_gpu: false               # Use CPU for VAD (lightweight)
  
  # ASR Provider (Qwen Cloud - Realtime WebSocket)
  # Speech recognition via Alibaba DashScope
  asr:
    provider: qwen-asr-realtime
    config:
      api_key: ${DASHSCOPE_API_KEY}
      model: "qwen3-asr-flash-realtime"
      language: "zh"
      sample_rate: 16000
  
  # Agent Provider (Qwen LLM via OpenAI-compatible API)
  # Language model for conversation
  agent:
    provider: openai-agent
    config:
      api_key: ${DASHSCOPE_API_KEY}
      model: "openai/qwen-plus"
      base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
      temperature: 0.7
      max_tokens: 2000
  
  # TTS Provider (Qwen Cloud - Realtime WebSocket)
  # Text-to-speech synthesis via Alibaba DashScope
  tts:
    provider: qwen-tts-realtime
    config:
      api_key: ${DASHSCOPE_API_KEY}
      model: "qwen3-tts-flash-realtime"
      voice: "Cherry"              # Available: Cherry, Zhichu, Zhixiaobai, etc.
      language_type: "Chinese"
      sample_rate: 16000

  # Vision Provider (Optional - for image analysis)
  vlm:
    provider: openai-vlm-remote
    config:
      model: "qwen-vl-max"
      api_key: "${DASHSCOPE_API_KEY}"
      base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
